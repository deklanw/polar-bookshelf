import { net } from 'electron';
import { Logger } from '../../logger/Logger';
import { Duplex, PassThrough, Readable, Stream } from 'stream';
import InterceptStreamProtocolRequest = Electron.InterceptStreamProtocolRequest;
import StreamProtocolResponse = Electron.StreamProtocolResponse;
import * as fs from 'fs';
import { Files } from '../../util/Files';

const log = Logger.create();

export class StreamInterceptors {
    public static mockInterceptor(
        request: InterceptStreamProtocolRequest,
        callback: StreamProtocolCallback
    ) {
        callback(<any>{
            statusCode: 200,
            headers: {
                'content-type': 'text/html',
            },
            data: createStream('HTTP 200 OK\r\n<h5>Response</h5>'),
        });
    }

    /**
     * Call the given lambda with setTimeout so it doesn't execute in the
     * foreground.
     *
     * This is a workaround to fix an Electron lockup issue.
     *
     * @param delegate
     */
    public static withSetTimeout(delegate: () => void) {
        setTimeout(() => {
            delegate();
        }, 0);
    }

    public static handleWithNetRequest(
        request: InterceptStreamProtocolRequest,
        callback: StreamProtocolCallback
    ) {
        log.debug('Handling request: ', request.url);

        const options = {
            method: request.method,
            url: request.url,
        };

        const responseStream = new PassThrough();

        const netRequest = net
            .request(options)
            .on('response', async response => {
                response
                    .on('data', chunk => {
                        responseStream.push(chunk);
                    })
                    .on('end', () => {
                        responseStream.push(null);
                    })
                    .on('aborted', () => {
                        log.error(`Response aborted: ${request.url}`);
                        callback(undefined); // TODO test this.
                    })
                    .on('error', () => {
                        log.error(`Response error: ${request.url}`);
                        callback(undefined); // TODO test this.
                    });

                const headers = Object.assign({}, response.headers);

                // We have to delete the content-encoding HTTP header because
                // the net.request API already performs the gzip/deflate
                // encoding FOR us and Chrome attempts to double decode it and
                // then breaks.
                delete headers['content-encoding'];

                const streamProtocolResponse: CorrectStreamProtocolResponse = {
                    headers,
                    data: responseStream,
                    statusCode: response.statusCode,
                };

                callback(streamProtocolResponse);
            })
            .on('abort', () => {
                log.error(`Request abort: ${request.url}`);
                callback(undefined); // TODO test this.
            })
            .on('error', error => {
                log.error(`Request error: ${request.url}`, error);
                callback(undefined); // TODO test this.
            });

        for (const header of Object.keys(request.headers)) {
            log.debug('Setting request header: ', header);
            const headerValue = (<any>request.headers)[header];
            netRequest.setHeader(header, headerValue);
        }

        if (request.uploadData) {
            // We have to call netRequest.write on all the request.uploadData.

            log.debug(`Writing data to request with method ${request.method}`);

            request.uploadData.forEach(current => {
                // TODO: we need to handle `blobUUID` and `file` which is valid
                // input.

                if (current.file) {
                    Files.readFileAsync(current.file)
                        .then(buffer => netRequest.write(buffer))
                        .catch(err => log.error('Could not upload: ', err));
                } else if (current.blobUUID) {
                    // FIXME: I think we have to use the blob: URL handler to fetch
                    // this data just like we would any normal URL then write the
                    // data to the connection. which is ugly.

                    throw new Error('Do not currently handle blobs');
                } else {
                    netRequest.write(this.assertChunk(current.bytes));
                }
            });

            // throw new TypeError('First argument must be a string or Buffer.')
        }

        netRequest.end();
    }

    private static assertChunk(chunk: Buffer): Buffer {
        if (chunk === undefined) {
            // TODO: we are getting this in
            throw new TypeError('Must not be undefined.');
        }

        if (chunk === null) {
            throw new TypeError('Must not be null.');
        }

        const chunkIsString = typeof chunk === 'string';
        const chunkIsBuffer = chunk instanceof Buffer;

        if (!chunkIsString && !chunkIsBuffer) {
            log.error('Invalid data given: ', chunk);
            throw new TypeError('Must be a string or Buffer.');
        }

        return chunk;
    }
}

// noinspection TsLint
export type StreamProtocolCallback = (
    stream?:
        | ReadableStream
        | StreamProtocolResponse
        | CorrectStreamProtocolResponse
) => void;

export interface CorrectStreamProtocolResponse {
    // Docs: http://electron.atom.io/docs/api/structures/stream-protocol-response

    /**
     * A Node.js readable stream representing the response body
     */
    data: ReadableStream | Readable | NodeJS.ReadableStream;
    /**
     * An object containing the response headers
     */
    headers: Electron.Headers;
    /**
     * The HTTP response code
     */
    statusCode: number;
}

function createStream(text: string) {
    const rv = new PassThrough();
    rv.push(text);
    rv.push(null);
    return rv;
}
